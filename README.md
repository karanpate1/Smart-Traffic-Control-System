# Smart Traffic Control & Violation Detection System

An automated traffic violation detection system leveraging Computer Vision and Deep Learning. This project detects multiple types of traffic violations in real-time, processes the data asynchronously using Redis, and extracts license plate numbers (ANPR) using PaddleOCR.

##  Features

* **Multi-Violation Detection**:
    * **Red Light Violation**: Detects vehicles crossing the stop line when the signal is red using HSV color thresholding and ROI mapping.
    * **Heavy Vehicle Restriction**: Identifies prohibited heavy vehicles (e.g., trucks) entering restricted zones using polygon ROIs.
    * **Wrong-Way Driving**: Calculates vehicle movement vectors to detect cars moving against the allowed flow of traffic 
* **Asynchronous Architecture**: Uses **Redis** as a message broker to decouple high-speed detection from heavy OCR processing, ensuring no frame drops during video analysis.
* **Automatic Number Plate Recognition (ANPR)**: Automatically crops vehicle images, detects license plates using a specialized YOLO model, and reads text using **PaddleOCR**.
* **Centralized Logging**: Saves annotated evidence images and maintains a consolidated `violations_log.json` database.
* **Parallel Execution**: A master script launches and manages all detection modules simultaneously.

---

##  System Architecture

The system follows a **Producer-Consumer** pattern:

1.  **Producers (Detection Scripts)**: These run on live video feeds. When a violation is detected, they save a snapshot and push metadata (bounding box, timestamp, violation type) to a **Redis Queue** (`violation_queue`).
2.  **Consumer (Processor Script)**: The `script2(final_json_writer).py` listens to the queue. It performs the computationally expensive tasks: detecting the number plate and running OCR.

---

##  Project Structure

| File Name | Description |
| :--- | :--- |
| `only_run_this.py` | **Master Script.** Runs the detection scripts and the OCR processor in parallel using `subprocess`. |
| `script2(final_json_writer).py` | **The Processor.** Consumes Redis messages, runs ANPR (PaddleOCR), draws plate text on images, and logs data to JSON. |
| `red_light_violation...py` | Detects vehicles running red lights. Requires setup of Traffic Light ROI and Road ROI. |
| `heavy_vehicle...py` | Detects trucks (Class ID 7) inside a predefined JSON polygon area. |
| `wrong_way...py` | Detects vehicles moving in the opposite direction of the defined vector. |

---

##  Prerequisites

1.  **Python 3.8+**
2.  **Redis Server**: Must be installed and running on `localhost:6379`.
3.  **Python Packages**:
    ```bash
    pip install opencv-python ultralytics paddlepaddle paddleocr redis numpy
    ```
4.  **Models**:
    * Place your YOLO vehicle model (e.g., `yolo11s.pt`) in the `models/` directory.
    * Place your Plate Detection model (`best(plate).pt`) in the `models/` directory.

---

##  Configuration

### 1. Region of Interest (ROI) Setup
The detection scripts rely on JSON files or manual input to know *where* to look.
* **Heavy Vehicle**: Reads `roi_data/heavy_vehicle_roi.json` for the restricted polygon.
* **Wrong Way**: Reads `roi_data/wrong_direction_rois.json` for the road area and correct direction vectors.
* **Red Light**: Uses an interactive UI on startup. You must manually draw the **Traffic Light ROI** and **Road ROI** using your mouse when the script starts.

### 2. Paths
Open any detection script (e.g., `heavy_vehicle...py`) and update the `INPUT_VIDEO_PATH` variable to point to your video file or camera source (e.g., `0` for webcam, `rtsp://...` for IP cams).

---

##  How to Run

You do not need to run the scripts individually. Use the master script to launch the entire ecosystem.

1.  **Start Redis Server** (Ensure it is running in the background).
2.  **Run the Master Script**:
    ```bash
    python only_run_this.py
    ```
    * This will automatically launch the `final_json_writer` and the detection scripts defined in the `scripts_to_run` list inside `only_run_this.py`.

### Stopping the System
Press **Ctrl+C** in the terminal running `only_run_this.py`. It will send a terminate signal to all child processes.

---

##  Outputs

The system generates three main types of output:

1.  **`annotated_images/`**: Raw snapshots taken immediately when a violation (Red Light, Wrong Way, or Heavy Vehicle) is detected. These contain the bounding box and violation label.
2.  **`final_images/`**: Processed images generated by the secondary script. These contain the original violation snapshot **plus** the extracted license plate text overlayed on the vehicle.
3.  **`violations_log.json`**: A structured database of all events.

###  Visual Examples

| 1. example 1 | 2. example 2 |
| :---: | :---: |
| <img src="E:\vmukti\anpr_pipeline\AI_Traffic_Control\final_images\violation_20250812_103835_20.jpg" width="400" alt="Violation Snapshot"> | <img src="final_images\violation_20250812_103837_1.jpg" width="400" alt="Final OCR Result"> |
| *System detects the violation (Wrong Way) and saves a rsult.* | *System detects the violation (Red light violation) and saves a rsult* |

### Sample Log Entry (`violations_log.json`)
```json
{
  "violation_20251217_1030.jpg": [
    {
      "class": "wrong_direction",
      "timestamp": "2025-12-17 10:30:45.123",
      "plate_text": "AH3595KO",
      "plate_confidence": 0.94,
      "final_image_path": "final_images/violation_20251217_1030.jpg"
    }
  ]
}